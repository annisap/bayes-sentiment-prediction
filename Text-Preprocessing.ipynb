{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Text Preprocessing & Sentiment Analysis on movie reviews with Naive Bayes \n",
    "- The Natural Language Toolkit (NLTK) is a platform used for processing textual data that will be later used in a text analysis program.\n",
    "- Naive Bayes is a classification algorithm used usually in text classification and in problems with multiple classes.\n",
    "- Sentiment Analysis is a text classification technique that assigns sentiment labels on words, sentences or documents. Here we use two sentiment labels: positive and negative\n",
    "- Movie reviews is a collection of reviews included in NLTK corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Text Preprocessing\n",
    "#### Tokenizing = splitting into parts\n",
    "Seperate sentence by words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Some',\n",
       " 'people',\n",
       " 'choose',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'ugliness',\n",
       " 'in',\n",
       " 'this',\n",
       " 'world',\n",
       " '.',\n",
       " 'The',\n",
       " 'disarray',\n",
       " '.',\n",
       " 'I',\n",
       " 'Choose',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'beauty',\n",
       " '.',\n",
       " 'You',\n",
       " 'should',\n",
       " \"n't\",\n",
       " 'eat',\n",
       " 'vegetables',\n",
       " 'and',\n",
       " 'honey',\n",
       " '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Tokenizer\n",
    "sentence = \"Some people choose to see the ugliness in this world. The disarray. I Choose to see the beauty. You shouldn't eat vegetables and honey.\"\n",
    "words = nltk.word_tokenize(sentence)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seperate sentence by periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Some people choose to see the ugliness in this world.', 'The disarray.', 'I Choose to see the beauty.', \"You shouldn't eat vegetables and honey.\"]\n"
     ]
    }
   ],
   "source": [
    "# Sentence Tokenizer\n",
    "print(sent_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach a part of speech tag to each word\n",
    "- VBZ, a verb\n",
    "- CC, a coordinating conjunction\n",
    "- RB, or adverbs; \n",
    "- IN, a preposition; \n",
    "- NN, a noun; \n",
    "- JJ, an adjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Some', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('choose', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('the', 'DT')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate parts of speech\n",
    "tagged = nltk.pos_tag(words)\n",
    "tagged[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using resources of NLTK\n",
    "- corpora: large collection of texts in different domains\n",
    "- lexicon: a list of words and their meanings\n",
    "- stopwords: uselless words for text analysis like is, at, to and so forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Some', 'people', 'choose', 'see', 'ugliness', 'world', '.', 'The', 'disarray', '.', 'I', 'Choose', 'see', 'beauty', '.', 'You', \"n't\", 'eat', 'vegetables', 'honey', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Extract stopwords from our sentence\n",
    "filtered_sentence =[w for w in words if not w in stopwords]\n",
    "\"\"\"\n",
    "The above line of code is equal to:\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopwords:\n",
    "    filtered_sentence.append(w)\n",
    "\"\"\"\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Semantic relations between words can be found via stemming and lemmatization. \n",
    "- Stemming: removes derivational affixes by applying a set of rules \n",
    "- Lemmatization: apply morphological analysis of words with the use of a vocabulary. \n",
    "    It can take into account synonyms and antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are\n",
      "is\n",
      "wa\n",
      "car\n",
      "car\n",
      "went\n",
      "import\n",
      "to\n",
      "poorli\n",
      "by\n",
      "goos\n",
      "best\n",
      "better\n"
     ]
    }
   ],
   "source": [
    "# Stemming \n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "words = ['are', 'is', 'was', 'car','cars', 'went', 'important','to', 'poorly', 'by', 'goose', 'best','better']\n",
    "\n",
    "for w in words:\n",
    "    print(stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are\n",
      "is\n",
      "wa\n",
      "car\n",
      "car\n",
      "went\n",
      "important\n",
      "to\n",
      "poorly\n",
      "by\n",
      "goose\n",
      "best\n",
      "better\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words_lem = ['are', 'is', 'was', 'car','cars', 'went', 'important','to', 'poorly', 'by', 'geese', 'best','better']\n",
    "for w in words_lem:\n",
    "    print(lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "loving\n",
      "love\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "# Passing the part of speech tag into the lemmatizer, gives more accurate results\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\")) # a->adjective\n",
    "print(lemmatizer.lemmatize('loving'))\n",
    "print(lemmatizer.lemmatize('loving', 'v')) # v->verb\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entities (ne) Chunking or Partial Parsing\n",
    "- Extracts short, well-formed phrases, or chunks, from a sentence\n",
    "- Needs part-of-speech annotations to add ne labels to the sentence. The output is a nltk.Tree object.\n",
    "\n",
    "- The ne_chunk produces 2-level trees:\n",
    "  - Nodes on Level-1: Outside any chunk, i.e. and/CC \n",
    "  - Nodes on Level-2: Inside a chunk , i.e. Mark/NNP, part of person chunk\n",
    "  - The label of the chunk is denoted by the label of the subtree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Mark/NNP)\n",
      "  and/CC\n",
      "  (PERSON John/NNP)\n",
      "  are/VBP\n",
      "  working/VBG\n",
      "  at/IN\n",
      "  (ORGANIZATION Google/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    " \n",
    "sentence = \"Mark and John are working at Google.\" \n",
    "print ne_chunk(pos_tag(word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet \n",
    "- Covers semantic and lexical relations between terms and their meaning such as synonymy, hyponymy and polysemy.\n",
    "- Synonyms for the word Success found in Google :victory, triumph,\tprosperity,  affluence, wealth, riches, fortune, opulence, luxury, comfort, benefit, gain, hapiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('success.n.01'),\n",
       " Synset('success.n.02'),\n",
       " Synset('success.n.03'),\n",
       " Synset('achiever.n.01')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "# synonyms\n",
    "syns = wordnet.synsets(\"success\")\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success.n.01\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "# Prints just the first example\n",
    "print(syns[0].name())\n",
    "# Prints just the word\n",
    "print(syns[0].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an event that accomplishes its intended purpose\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u\"let's call heads a success and tails a failure\", u'the election was a remarkable success for the Whigs']\n"
     ]
    }
   ],
   "source": [
    "# Examples of the word in use\n",
    "print(syns[0].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synonym vs Synset \n",
    "- synonym: a word or phrase with a meaning that is the same as, or very similar to, another word or phrase \n",
    "- synset: a set of one or more synonyms that are interchangeable in some context  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets(set([u'beneficial', u'right', u'secure', u'just', u'unspoilt', u'respectable', u'good', u'goodness', u'dear', u'salutary', u'ripe', u'expert', u'skillful', u'in_force', u'proficient', u'unspoiled', u'dependable', u'soundly', u'honorable', u'full', u'undecomposed', u'safe', u'adept', u'upright', u'trade_good', u'sound', u'in_effect', u'practiced', u'effective', u'commodity', u'estimable', u'well', u'honest', u'near', u'skilful', u'thoroughly', u'serious']))\n",
      "antonyms(set([u'bad', u'badness', u'ill', u'evil', u'evilness']))\n"
     ]
    }
   ],
   "source": [
    "# Print synonyms & antoyms of 'good'\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name()) #take just the first lemma, instead of the whole set\n",
    "\n",
    "print('synsets({})'.format(set(synonyms)))\n",
    "print('antonyms({})'.format(set(antonyms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('success.n.01')\n",
      "Synset('success.n.02')\n",
      "Synset('success.n.03')\n",
      "Synset('achiever.n.01')\n"
     ]
    }
   ],
   "source": [
    "# Print 'similar to' words \n",
    "for ss in wordnet.synsets('success'):\n",
    "    print(ss)\n",
    "    for sim in ss.similar_tos():\n",
    "        print('    {}'.format(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909090909091\n"
     ]
    }
   ],
   "source": [
    "# Semantics Similarity\n",
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('boat.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
